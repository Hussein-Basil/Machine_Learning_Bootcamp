{"cells":[{"cell_type":"markdown","metadata":{"id":"Hd4Lz8wkfcdj"},"source":["# Feature Selection\n","\n","\n","{{ badge }}\n","\n","Feature selection is a process where you automatically or manually select those features in your data that contribute most to the prediction variable or output in which you are interested.\n","\n","There are many ways to perform feature selection. Some methods include:\n","\n","- Using a correlation matrix to select features that are highly correlated with the output variable\n","- Using a statistical tests (e.g., $x^2$) to measure the statistical significance of each feature in relation to the label. \n","- Using a recursive feature elimination algorithm to automatically select features that are most relevant to the output variable\n","\n","Feature selection is important in machine learning because it can help you reduce the amount of data you need to work with, which in turn can reduce the amount of time and resources required to train and tune your machine learning model. Additionally, by selecting only the most relevant features, you can improve the interpretability of your machine learning model and make overfitting less likley to occure.\n","\n","There are many feature selection techniques supported by Scikit Learn. We will go through some of them and if you wish to learn more visit [Scikit Learn's Documentation](https://scikit-learn.org/stable/modules/feature_selection.html)."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656017239448,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"3euJPnU0fcCU"},"outputs":[],"source":["from sklearn import datasets, model_selection, feature_selection, svm, metrics"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1656017243343,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"4zwq1k1zfae4","outputId":"db6bf912-6191-4194-caa9-c2aa8b58d9b5"},"outputs":[{"data":{"text/plain":["(569, 30)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Load iris dataset\n","x, y = datasets.load_breast_cancer(return_X_y=True)\n","\n","x.shape"]},{"cell_type":"markdown","metadata":{"id":"U5FBvhd5-EBE"},"source":["## Feature Selection Methods"]},{"cell_type":"markdown","metadata":{"id":"iZStJ23HkfrE"},"source":["### Univariate Feature Selection\n","\n","Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator.\n","\n","We will be using the `SelectKBest` class from Scikit Learn which returing the best $k$ features using some scoring method based on a statistical significance test like $x^2$ (chi-square).\n","\n","Scikit Learn includes additional scoring functions like:\n","\n","- For classification: `chi2`, `f_classif`, `mutual_info_classif`\n","- For regression: `f_regression`, `mutual_info_regression`\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1656017248783,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"zdIpHV6nwaEb","outputId":"6c922aa7-b06b-4f9c-9b13-d451ae705f32"},"outputs":[{"data":{"text/plain":["(569, 10)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Define the feature selector by selecing the scoring function and the number of features to select\n","feature_selector = feature_selection.SelectKBest(feature_selection.chi2, k=10)\n","\n","# Use fit transform to train the feature selector and return the best 10 features\n","x_new = feature_selector.fit_transform(x, y)\n","\n","# New X will have 10 features instead of 30\n","x_new.shape"]},{"cell_type":"markdown","metadata":{"id":"OCF8uyvr5DKS"},"source":["### Recursive Feature Elimination\n","\n","Given an external estimator that assigns weights to features (e.g., the coefficients/weights of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute (such as `coef_`, `feature_importances_`). Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1656017249268,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"l6AXNXt0805y","outputId":"f29b7221-482e-4dee-c5db-c2bab9014991"},"outputs":[{"data":{"text/plain":["(569, 10)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# We use a linear kernel because RFE requires a model that has a coef_ or feature_importances_ attributes\n","svc = svm.SVC(kernel='linear')\n","\n","# Define the feature selector by selecing the estimator and the number of features to select, and the number of features to remove in each iteration\n","rfe = feature_selection.RFE(estimator=svc, n_features_to_select=10, step=1)\n","\n","# Use fit transform to train the feature selector and return the best 10 features\n","x_new = rfe.fit_transform(x, y)\n","\n","# New X will have 10 features instead of 30\n","x_new.shape"]},{"cell_type":"markdown","metadata":{"id":"emX3sGCwyc92"},"source":["## Training & Evaluating"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1656017249270,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"UoVEg8slyZTo"},"outputs":[],"source":["use_pruned_features = True #@param {type:\"boolean\"}\n","x_final = x_new if use_pruned_features else x\n","\n","x_train, x_test, y_train, y_test = model_selection.train_test_split(x_final, y, test_size=0.3, stratify=y, random_state=42)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1656017249271,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"fhKL3ElPyuBu","outputId":"1b0f3b23-6174-459e-e121-063a2964bddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model on 10 features\n"]},{"data":{"text/plain":["SVC()"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"Training model on {x_train.shape[1]} features\")\n","\n","# Define a Support Vector Machine classifier with default configuration\n","model = svm.SVC()\n","\n","# Train model using the training dataset\n","model.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1656017249272,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"9dusZZULy_Jq","outputId":"3dfa36dc-79cc-4cbb-9b8c-2922fcaf32ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9005847953216374\n","Precision: 0.8813559322033898\n","Recall: 0.9719626168224299\n"]}],"source":["# Use the model to predict the testing set to prepare for calculating the metrics\n","y_pred = model.predict(x_test)\n","\n","# Calculate and print relevant scores\n","accuracy = metrics.accuracy_score(y_test, y_pred)\n","precision = metrics.precision_score(y_test, y_pred)\n","recall = metrics.recall_score(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"]},{"cell_type":"markdown","metadata":{"id":"gkav1r_6QLHz"},"source":["# Feature selection using Select From Model"]},{"cell_type":"markdown","metadata":{"id":"eF3dd6CnQVuS"},"source":["[SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel) is a meta-transformer that can be used alongside any estimator that assigns importance to each feature through a specific attribute (such as coef_, feature_importances_) or via an importance_getter callable after fitting. \n","\n","The features are considered unimportant and removed if the corresponding importance of the feature values are below the provided threshold parameter. \n","\n","Apart from specifying the threshold numerically, there are built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”. \n","\n","In combination with the threshold criteria, one can use the max_features parameter to set a limit on the number of features to select."]},{"cell_type":"markdown","metadata":{"id":"jQ7k6NsdV216"},"source":["## Define and Train the Linear Model"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":845,"status":"ok","timestamp":1656017493782,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"2ks-dw3vT7tx","outputId":"6ee32603-f405-4613-8f85-f06bb3c32bb5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"data":{"text/plain":["LinearSVC()"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["lsvc = svm.LinearSVC()\n","lsvc.fit(x, y)"]},{"cell_type":"markdown","metadata":{"id":"MzkHBxM1V_eN"},"source":["## Use the Trained Linear Model to Get the Best Features"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656017495037,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"a7YXLQWLUBup","outputId":"3fb2ae73-6903-40a0-d345-2d49465ab7f2"},"outputs":[{"data":{"text/plain":["(569, 9)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model = feature_selection.SelectFromModel(lsvc, prefit=True)\n","x_new =model.transform(x)# get the best features using the pretrained model\n","x_new.shape"]},{"cell_type":"markdown","metadata":{"id":"3dugS7ARWgKE"},"source":["## Split the Datase to Train and Test "]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656017495527,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"0VRTE-r8UPtb"},"outputs":[],"source":["x_train, x_test, y_train, y_test = model_selection.train_test_split(x_new, y, test_size=0.3, stratify=y, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"nN_DtPG8Vrc9"},"source":["## Training & Evaluating"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656017496445,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"T9O9CXCCU9ll","outputId":"9d638f17-a3f4-4b9b-d172-3efe1d363ae2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model on 9 features\n"]},{"data":{"text/plain":["SVC()"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"Training model on {x_train.shape[1]} features\")\n","\n","# Define a Support Vector Machine classifier with default configuration\n","model = svm.SVC()\n","\n","# Train model using the training dataset\n","model.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656017497966,"user":{"displayName":"Muntadher Al-kaabi","userId":"00221067971932357642"},"user_tz":-180},"id":"EH4fPo7eVCF5","outputId":"f867310d-fd0f-4c5b-c010-c934c1492971"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9415204678362573\n","Precision: 0.9292035398230089\n","Recall: 0.9813084112149533\n"]}],"source":["# Use the model to predict the testing set to prepare for calculating the metrics\n","y_pred = model.predict(x_test)\n","\n","# Calculate and print relevant scores\n","accuracy = metrics.accuracy_score(y_test, y_pred)\n","precision = metrics.precision_score(y_test, y_pred)\n","recall = metrics.recall_score(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"1- Feature Selection.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
